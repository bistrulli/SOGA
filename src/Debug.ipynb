{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa5e2d3-2260-471c-adc0-83ca1a02a269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sogaPreprocessor import *\n",
    "from producecfg import *\n",
    "from libSOGA import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d1f45b-f3af-49fb-93df-13d3564240fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example of posterior computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7bd5f05-5db1-44f2-ab3f-fd3c8c3b23b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntryNode<> Dist<['theta', 'y'],pi: [1.0]  mu: [tensor([0., 0.], requires_grad=True)] sigma: [tensor([[1.0000e-08, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-08]])]>\n",
      "True\n",
      "StateNode<state0,None,theta=gm([0.5, 0.5],[0.25, 0.75],[0.1443, 0.1443])> Dist<['theta', 'y'],pi: [1.0]  mu: [tensor([0., 0.], requires_grad=True)] sigma: [tensor([[1.0000e-08, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-08]])]>\n",
      "True\n",
      "TestNode<test0,gm([0.5, 0.5],[0.25, 0.75],[0.1443, 0.1443])-theta<0> Dist<['theta', 'y'],pi: [0.5, 0.5]  mu: [tensor([0.2500, 0.0000], grad_fn=<CopySlices>), tensor([0.7500, 0.0000], grad_fn=<CopySlices>)] sigma: [tensor([[2.0822e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-08]]), tensor([[2.0822e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-08]])]>\n",
      "True\n",
      "StateNode<state1,True,y=gm([1.],[0.],[0.01])> Dist<['theta', 'y'],pi: [0.5, 0.5]  mu: [tensor([0.2500, 0.0000], grad_fn=<CopySlices>), tensor([0.7500, 0.0000], grad_fn=<CopySlices>)] sigma: [tensor([[2.0822e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-08]]), tensor([[2.0822e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-08]])]>\n",
      "True\n",
      "StateNode<state2,False,y=gm([1.],[1.],[0.01])> Dist<['theta', 'y'],pi: [0.5, 0.5]  mu: [tensor([0.2500, 0.0000], grad_fn=<CopySlices>), tensor([0.7500, 0.0000], grad_fn=<CopySlices>)] sigma: [tensor([[2.0822e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-08]]), tensor([[2.0822e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-08]])]>\n",
      "True\n",
      "MergeNode<merge0> Dist<['theta', 'y'],pi: [tensor(0.2500), tensor(0.4964), tensor(0.0036), tensor(0.2500)]  mu: [tensor([0.1686, 1.0000], grad_fn=<CopySlices>), tensor([0.2480, 1.0000], grad_fn=<CopySlices>), tensor([0.4666, 1.0000], grad_fn=<CopySlices>), tensor([0.6686, 1.0000], grad_fn=<CopySlices>)] sigma: [tensor([[1.4194e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-04]], grad_fn=<CopySlices>), tensor([[2.0309e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-04]], grad_fn=<CopySlices>), tensor([[1.1360e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-04]], grad_fn=<CopySlices>), tensor([[1.4195e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-04]], grad_fn=<CopySlices>)]>\n",
      "True\n",
      "MergeNode<merge0> Dist<['theta', 'y'],pi: [tensor(0.2500), tensor(0.4964), tensor(0.0036), tensor(0.2500)]  mu: [tensor([0.1686, 1.0000], grad_fn=<CopySlices>), tensor([0.2480, 1.0000], grad_fn=<CopySlices>), tensor([0.4666, 1.0000], grad_fn=<CopySlices>), tensor([0.6686, 1.0000], grad_fn=<CopySlices>)] sigma: [tensor([[1.4194e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-04]], grad_fn=<CopySlices>), tensor([[2.0309e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-04]], grad_fn=<CopySlices>), tensor([[1.1360e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-04]], grad_fn=<CopySlices>), tensor([[1.4195e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-04]], grad_fn=<CopySlices>)]>\n",
      "True\n",
      "ExitNode<> None\n"
     ]
    }
   ],
   "source": [
    "compiledFile=compile2SOGA('../programs/SOGA/BernoulliTorch.soga')\n",
    "cfg = produce_cfg(compiledFile)\n",
    "output_dist = start_SOGA(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f220cd-b277-476b-a241-69b900d14e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19.8476], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dist.gm.marg_pdf(torch.tensor(0.001), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5356113e-ee71-47fc-9b50-e352b4a8c9ba",
   "metadata": {},
   "source": [
    "### Example of gradient-based optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc32fd89-c025-4197-beca-57339a396dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiledFile=compile2SOGA('../programs/SOGA/Optim.soga')\n",
    "cfg = produce_cfg(compiledFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d479266e-cbdf-4bc7-b211-c7a7fa84b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_posterior(init_mean):\n",
    "    # initializes current_dist\n",
    "    var_list = cfg.ID_list\n",
    "    data = cfg.data\n",
    "    gm = GaussianMix([torch.tensor(1.)], [init_mean], [torch.eye(len(var_list))])\n",
    "    init_dist = Dist(var_list, gm)\n",
    "    cfg.root.set_dist(init_dist)\n",
    "\n",
    "    # initializes visit queue\n",
    "    exec_queue = [cfg.root]\n",
    "\n",
    "    # executes SOGA on nodes on exec_queue\n",
    "    while(len(exec_queue)>0):\n",
    "        SOGA(exec_queue.pop(0), data, False, exec_queue)\n",
    "\n",
    "    return cfg.node_list['exit'].dist\n",
    "    \n",
    "    # returns output distribution\n",
    "    #p, current_dist = merge(cfg.node_list['exit'].list_dist)\n",
    "    #cfg.node_list['exit'].list_dist = []\n",
    "    #return current_dist\n",
    "\n",
    "def compute_posterior_dummy(init_mean):\n",
    "    var_list = cfg.ID_list\n",
    "    dist = Dist(var_list, GaussianMix([1.], [init_mean], [torch.eye(len(var_list))]))\n",
    "    new_dist = update_rule(dist, 'm = gm([1.], [0.], [1.])', {})\n",
    "    #new_dist = update_rule(dist, 'skip', {})\n",
    "    return new_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f9934e-207c-4224-b475-b2e0f760d523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dist<['m'],pi: [tensor(1.)]  mu: [tensor([0.], grad_fn=<CloneBackward0>)] sigma: [tensor([[2.]])]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_mean = torch.tensor([0.0], requires_grad=True)  # Starting point for init_mean\n",
    "init_mean = torch.nn.Parameter(init_mean)\n",
    "\n",
    "entry_dist = compute_posterior(init_mean)\n",
    "entry_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3324f797-9a95-4f6a-8306-9b104465c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = distributions.Normal(torch.tensor(5.), torch.tensor(1.)).sample((100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "940e5c04-061c-47db-9477-008f996893cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_likelihood(dist, samples):\n",
    "    likelihood = torch.tensor([0.])\n",
    "    for sample in samples:\n",
    "        likelihood += current_dist.gm.marg_pdf(sample,0)\n",
    "    return -likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e320eb98-ae82-4c9d-8434-806fe1a7d90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0.036618512123823166, loss: -0.18703266978263855\n",
      "x: 0.6156790256500244, loss: -0.49764034152030945\n",
      "x: 3.7490010261535645, loss: -10.335077285766602\n",
      "x: 5.0711774826049805, loss: -23.728288650512695\n",
      "x: 5.0711774826049805, loss: -23.728290557861328\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Ensure init_mean is a Parameter so it can be optimized\n",
    "init_mean = torch.tensor([0.0], requires_grad=True)  # Starting point for init_mean\n",
    "init_mean = torch.nn.Parameter(init_mean)\n",
    "\n",
    "# Define the optimizer with init_mean as the parameter\n",
    "optimizer = torch.optim.SGD([init_mean], lr=0.1)\n",
    "\n",
    "for i in range(50):\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "    \n",
    "    # loss\n",
    "    current_dist = compute_posterior(init_mean)\n",
    "    loss = neg_likelihood(current_dist, samples)\n",
    "    \n",
    "    # Backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update init_mean\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print progress\n",
    "    if i % 10 == 0:\n",
    "        print(f\"x: {init_mean.item()}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19135642-56cc-46aa-90aa-2394b944328f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
