{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37003ad4-ff8f-46a8-a0cd-98193f3b3969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "from TRUNCLexer import *\n",
    "from TRUNCParser import *\n",
    "from TRUNCListener import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152ff573-c3b9-490d-805e-901cf86161ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ineq_func(self,comp):\n",
    "    mu = comp.gm.mu[0]\n",
    "    sigma = comp.gm.sigma[0]\n",
    "    final_pi = []\n",
    "    final_mu = []\n",
    "    final_sigma = []\n",
    "    for part in product(*[range(len(mean)) for mean in self.aux_means]):\n",
    "        # for a given combination of components of the auxiliary variables, creates a new component extending comp\n",
    "        aux_pi = 1\n",
    "        aux_mean = list(copy(mu))\n",
    "        aux_sigma = []\n",
    "        ineq_coeff = np.array(copy(self.coeff))\n",
    "        ineq_const = self.const\n",
    "        for p,q in zip(range(len(self.aux_means)), part):\n",
    "            aux_pi = aux_pi*self.aux_pis[p][q]\n",
    "            aux_mean.append(self.aux_means[p][q])\n",
    "            aux_sigma.append(self.aux_covs[p][q])\n",
    "        aux_mean = np.array(aux_mean)\n",
    "        aux_sigma = np.diag(aux_sigma)\n",
    "        aux_cov = np.block([[sigma, np.zeros((len(sigma), len(aux_sigma)))], [np.zeros((len(aux_sigma), len(sigma))), aux_sigma]])\n",
    "        # substitute deltas\n",
    "        delta_idx = np.where(np.diag(aux_cov) < delta_tol)[0]\n",
    "        ineq_const -= np.array(self.coeff)[delta_idx].dot(aux_mean[delta_idx])\n",
    "        ineq_coeff[delta_idx] = np.zeros(len(delta_idx))\n",
    "        # if all variables were deltas return\n",
    "        if np.all(np.array(ineq_coeff) == 0):\n",
    "            if (self.type == '>' and ineq_const < 0) or (self.type == '>=' and ineq_const <= 0) or (self.type == '<' and ineq_const > 0) or (self.type == '<=' and ineq_const >= 0):\n",
    "                new_P = 1.\n",
    "            else:\n",
    "                new_P = 0.\n",
    "            new_mu = mu\n",
    "            new_sigma = sigma\n",
    "        # else compute truncated distribution\n",
    "        else:\n",
    "            # STEP 1: change variables\n",
    "            norm = np.linalg.norm(ineq_coeff)\n",
    "            ineq_coeff = np.array(ineq_coeff)/norm\n",
    "            ineq_const = ineq_const/norm\n",
    "            A = find_basis(ineq_coeff)           # maybe instead of A a vector can be used to improve scalability (?)\n",
    "            transl_mu = A.dot(aux_mean)\n",
    "            transl_sigma = A.dot(aux_cov).dot(A.transpose())\n",
    "            # STEP 2: finds the indices of the components that needs to be transformed\n",
    "            transl_alpha = np.zeros(len(transl_mu))\n",
    "            transl_alpha[0] = 1\n",
    "            indices = select_indices(transl_alpha, transl_sigma)\n",
    "            # STEP 3: creates reduced vectors taking into account only the coordinates that need to be transformed\n",
    "            red_transl_alpha = reduce_indices(transl_alpha, indices)\n",
    "            red_transl_mu = reduce_indices(transl_mu, indices)\n",
    "            red_transl_sigma = reduce_indices(transl_sigma, indices) \n",
    "            # STEP 4: creates the hyper-rectangle to integrate on\n",
    "            a = np.ones(len(red_transl_alpha))*(-np.inf)\n",
    "            b = np.ones(len(red_transl_alpha))*(np.inf)\n",
    "            if self.type=='>' or self.type=='>=':\n",
    "                a[0] = ineq_const\n",
    "            if self.type=='<' or self.type=='<=':\n",
    "                b[0] = ineq_const   \n",
    "            # STEP 5: compute moments in the transformed coordinates\n",
    "            new_P, new_red_transl_mu, new_red_transl_sigma = compute_moments(red_transl_mu, red_transl_sigma, a, b)\n",
    "            # STEP 6: recreates extended vectors\n",
    "            new_transl_mu = extend_indices(new_red_transl_mu, transl_mu, indices)\n",
    "            new_transl_sigma = extend_indices(new_red_transl_sigma, transl_sigma, indices)\n",
    "            # STEP 7: goes back to older coordinates\n",
    "            d = len(comp.var_list)\n",
    "            A_inv = np.linalg.inv(A)\n",
    "            new_mu = A_inv.dot(new_transl_mu)[:d]\n",
    "            new_sigma = A_inv.dot(new_transl_sigma).dot(A_inv.transpose())[:d,:d]\n",
    "            end = time()\n",
    "        # append new values\n",
    "        final_pi.append(aux_pi*new_P)\n",
    "        final_mu.append(new_mu)\n",
    "        final_sigma.append(new_sigma)\n",
    "    return GaussianMix(final_pi, final_mu, final_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe63e4e-2b97-4503-af8c-dd0df26cf0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruncRule(TRUNCListener):\n",
    "    \n",
    "    def __init__(self, var_list, data):\n",
    "        self.var_list = var_list\n",
    "        self.data = data\n",
    "        self.type = None\n",
    "        self.coeff = torch.zeros(len(var_list))\n",
    "        self.const = torch.tensor(0.)\n",
    "        self.func = None\n",
    "        \n",
    "        self.aux_pis = []\n",
    "        self.aux_means = []\n",
    "        self.aux_covs = []\n",
    "        \n",
    "    def enterIneq(self, ctx):\n",
    "        self.type = ctx.inop().getText()\n",
    "        if not ctx.const().NUM() is None:\n",
    "            self.const = torch.tensor(float(ctx.const().NUM().getText()))\n",
    "        elif not ctx.const().idd() is None:\n",
    "            self.const = ctx.const().idd().getValue(self.data)\n",
    "                \n",
    "    \n",
    "    def enterLexpr(self, ctx):\n",
    "        self.flag_sign = torch.tensor(1.)\n",
    "\n",
    "            \n",
    "    def exitLexpr(self, ctx):\n",
    "        self.func = partial(ineq_func,self)\n",
    "        \n",
    "        \n",
    "    def enterMonom(self,ctx):\n",
    "        if ctx.var().gm() is None:\n",
    "            # monom in the form const? '*' (IDV | idd)\n",
    "            ID = ctx.var()._getText(self.data)\n",
    "            if not ctx.const() is None:\n",
    "                if not ctx.const().NUM() is None:\n",
    "                    coeff = self.flag_sign*torch.tensor(float(ctx.const().NUM().getText()))\n",
    "                elif not ctx.const().idd() is None:\n",
    "                    coeff = self.flag_sign*torch.tensor(ctx.const().idd().getValue(self.data))\n",
    "            else:\n",
    "                coeff = self.flag_sign\n",
    "            idx = self.var_list.index(ID)\n",
    "            self.coeff[idx] = coeff\n",
    "        # monom in the form const? '*' gm\n",
    "        else:\n",
    "            self.aux_pis.append(torch.tensor(eval(ctx.var().gm().list_()[0].getText())))\n",
    "            self.aux_means.append(torch.tensor(eval(ctx.var().gm().list_()[1].getText())))\n",
    "            self.aux_covs.append(torch.pow(torch.tensor(eval(ctx.var().gm().list_()[2].getText())),2))\n",
    "            if not ctx.const() is None:\n",
    "                if not ctx.const().NUM() is None:\n",
    "                    coeff = self.flag_sign*torch.tensor(float(ctx.const().NUM().getText()))\n",
    "                elif not ctx.const().idd() is None:\n",
    "                    coeff = self.flag_sign*torch.tensor(ctx.const().idd().getValue(self.data))\n",
    "            else:\n",
    "                coeff = self.flag_sign \n",
    "            self.coeff = torch.hstack([self.coeff, coeff])            \n",
    "            \n",
    "    def enterSub(self, ctx):\n",
    "        self.flag_sign = torch.tensor(-1.)\n",
    "        \n",
    "    def enterSum(self, ctx):\n",
    "        self.flag_sign = torch.tensor(1.)\n",
    "        \n",
    "    def enterEq(self, ctx):\n",
    "        self.type = ctx.eqop().getText()\n",
    "        idx = self.var_list.index(ctx.var()._getText(self.data))\n",
    "        self.coeff[idx] = torch.tensor(1.)\n",
    "        if not ctx.const() is None:\n",
    "            if not ctx.const().NUM() is None:\n",
    "                self.const = torch.tensor(float(ctx.const().NUM().getText()))\n",
    "            elif not ctx.const().idd() is None:\n",
    "                self.const = torch.tensor(ctx.const().idd().getValue(self.data))\n",
    "        self.func = partial(eq_func,self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b83a33b1-54c7-4961-8185-b6435eeae1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc = '0.5*gm([0.5, 0.5], [0.,1.], [1.,1.]) > 0'\n",
    "var_list = ['x', 'y']\n",
    "data = {}\n",
    "\n",
    "lexer = TRUNCLexer(InputStream(trunc))\n",
    "stream = CommonTokenStream(lexer)\n",
    "parser = TRUNCParser(stream)\n",
    "tree = parser.trunc()\n",
    "trunc_rule = TruncRule(var_list, data)\n",
    "walker = ParseTreeWalker()\n",
    "walker.walk(trunc_rule, tree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ec08192-57fa-462b-88b5-b99ceb07b0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.5000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_rule.var_list\n",
    "trunc_rule.data\n",
    "trunc_rule.type\n",
    "trunc_rule.coeff \n",
    "#trunc_rule.const\n",
    "#trunc_rule.func\n",
    "#trunc_rule.aux_pis\n",
    "#trunc_rule.aux_means\n",
    "#trunc_rule.aux_covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7336a66e-63e5-4183-88f8-3636b84d1f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c0dec-7a0d-47dc-9ca1-a9a26a397419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
